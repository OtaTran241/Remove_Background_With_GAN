# Background Removal using GAN with PyTorch

This project implements a Generative Adversarial Network (GAN) to perform background removal from images. The model is trained to generate images without backgrounds given images with backgrounds, effectively learning the task of background subtraction.

## Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
  - [Generator (GModel)](#generator-gmodel)
  - [Discriminator (DModel)](#discriminator-dmodel)
- [Training](#training)
- [Inference](#inference)
- [Dependencies](#dependencies)
- [Usage](#usage)
  - [Training the Model](#training-the-model)
  - [Generating Images](#generating-images)
- [Results](#results)
- [Contributing](#contributing)

## Project Overview
This project leverages a GAN consisting of a generator (`GModel`) and a discriminator (`DModel`) to remove backgrounds from images. The generator learns to produce images without backgrounds, while the discriminator differentiates between real images (with no background) and generated images.

## Dataset
The dataset used in this project consists of paired images:
- **Images with backgrounds**: Input images that contain the background.
- **Images without backgrounds**: Target images that do not have the background.

Dataset link [here](https://www.kaggle.com/datasets/cooperbuch/images-with-no-background-for-background-removal)

## Model Architecture

### Generator (GModel)
The generator is built using a U-Net-like architecture with encoder-decoder layers:
- **Encoder**: Consists of convolutional layers to downsample the input image.
- **Decoder**: Uses transpose convolutions to upsample the image, producing an output image without background.

### Discriminator (DModel)
The discriminator is a convolutional neural network (CNN) designed to classify images as real (without background) or fake (generated by the generator). It uses residual blocks to enhance feature extraction.

## Training
## Training

The training process of the GAN involves two main components: the generator and the discriminator. The generator creates fake images, and the discriminator tries to distinguish between real images and the ones generated by the generator. The process alternates between updating the discriminator and the generator:

1. **Discriminator Update**: The discriminator is trained to correctly identify real images from fake ones. It minimizes the Binary Cross-Entropy (BCE) loss for this task.
   
2. **Generator Update**: The generator is trained to fool the discriminator into classifying its fake images as real. It minimizes the BCE loss to make the discriminator believe that its generated images are real. Additionally, L1 loss (Mean Absolute Error) is used to ensure that the generated images are close to the true images in terms of pixel values.

### Training Hyperparameters
- **Batch Size**: 55
- **Epochs**: 200
- **Learning Rate**:
  - Generator: 1e-4
  - Discriminator: 1e-5

### Code Explanation

```python
def train_gan(train_loader, test_loader, generator, discriminator, optimizer_G, optimizer_D, bce, l1loss, 
              num_epochs, device='cuda', last_checkpoint_dir="models/last_checkpoint.pth"):
```
This function trains the GAN model, alternating between training the generator and the discriminator. The function takes in data loaders, the generator and discriminator models, optimizers, loss functions, and training parameters as inputs.

```python
    writer = SummaryWriter('runs/gan_experiment')
    start_epoch = 0
    best_g_loss = float('inf')
    best_d_loss = float('inf')
```
Here, a SummaryWriter is initialized for TensorBoard logging. The variables start_epoch, best_g_loss, and best_d_loss are initialized to track the starting epoch and the best losses during training.

```python
    if os.path.exists(last_checkpoint_dir):
        checkpoint = torch.load(last_checkpoint_dir, map_location=device)
        generator.load_state_dict(checkpoint['generator'])
        discriminator.load_state_dict(checkpoint['discriminator'])
        optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])
        optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_d_loss = checkpoint['best_d_loss']
        best_g_loss = checkpoint['best_g_loss']
        print("Loaded the last model and continued training from epoch", start_epoch)
    else:
        print("Checkpoint not found, training from scratch")
```
This block checks if a checkpoint file exists. If it does, it loads the saved model state, optimizers, and previous epoch details to resume training from where it was left off. If not, training starts from scratch.

```python
    os.makedirs("models", exist_ok=True)
```
This ensures the models directory exists for saving model checkpoints.

```python
    for epoch in range(start_epoch, num_epochs):
        discriminator.train()
        generator.train()
        discriminator_epoch_loss, generator_epoch_loss = 0, 0
```
The training loop starts, iterating over the number of epochs. Both the discriminator and generator are set to training mode, and losses are initialized for each epoch.

```python
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs, true_images = inputs.to(device), targets.to(device)

            ###### Train D Model
            optimizer_D.zero_grad()

            fake_images = generator(inputs)
            pred_fake = discriminator(fake_images).to(device)
            loss_fake = bce(pred_fake, torch.zeros_like(pred_fake, device=device))

            pred_real = discriminator(true_images).to(device)
            loss_real = bce(pred_real, torch.ones_like(pred_real, device=device))

            loss_D = (loss_fake + loss_real) / 2

            loss_D.backward()
            optimizer_D.step()

            discriminator_epoch_loss += loss_D.item()
```
For each batch, the discriminator is trained first. The generator produces fake_images, and the discriminator predicts whether each image is real or fake. The BCE loss is calculated for both the fake and real predictions, and the discriminator's loss (loss_D) is updated accordingly. The discriminator's weights are then updated using optimizer_D.

```python
            ###### Train G Model
            optimizer_G.zero_grad()

            fake_images = generator(inputs)
            pred_fake = discriminator(fake_images).to(device)
            loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))
            loss_G_l1 = l1loss(fake_images, true_images) * 100
            loss_G = loss_G_bce + loss_G_l1

            loss_G.backward()
            optimizer_G.step()

            generator_epoch_loss += loss_G.item()
```
Next, the generator is trained. The generator creates fake images again, which are fed to the discriminator. The generator's goal is to minimize the BCE loss (loss_G_bce), making the discriminator believe that the fake images are real. The L1 loss (loss_G_l1) ensures the fake images resemble the real ones in terms of pixel values. The total generator loss (loss_G) is then calculated and backpropagated, and the generator's weights are updated using optimizer_G.

```python
        discriminator_epoch_loss /= len(train_loader)
        generator_epoch_loss /= len(train_loader)

        print(f"Epoch [{epoch}/{num_epochs}], D Loss: {discriminator_epoch_loss:.4f}, G Loss: {generator_epoch_loss:.4f}")
```
The average loss for both the discriminator and generator is calculated for the epoch and printed.

```python
        discriminator.eval()
        generator.eval()

        discriminator_epoch_val_loss, generator_epoch_val_loss = 0, 0

        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.to(device), targets.to(device)

                fake_images = generator(inputs).detach()
                pred_fake = discriminator(fake_images).to(device)

                loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))
                loss_G_l1 = l1loss(fake_images, targets) * 100
                loss_G = loss_G_bce + loss_G_l1
                loss_D = bce(pred_fake.to(device), torch.zeros_like(pred_fake, device=device))

                discriminator_epoch_val_loss += loss_D.item()
                generator_epoch_val_loss += loss_G.item()

        discriminator_epoch_val_loss /= len(test_loader)
        generator_epoch_val_loss /= len(test_loader)

        print(f"Validation Epoch [{epoch}/{num_epochs}] - D Loss: {discriminator_epoch_val_loss:.4f}, G Loss: {generator_epoch_val_loss:.4f}")
```
The model is evaluated on the validation set without updating the weights. The generator and discriminator are set to evaluation mode, and the losses are calculated over the validation data.

```python
        if discriminator_epoch_loss < best_d_loss:
            best_d_loss = discriminator_epoch_loss
            torch.save({
                'generator': generator.state_dict(),
                'discriminator': discriminator.state_dict(),
                'optimizer_G_state_dict': optimizer_G.state_dict(),
                'optimizer_D_state_dict': optimizer_D.state_dict(),
                'epoch': epoch,
                'best_g_loss': best_g_loss,
                'best_d_loss': best_d_loss
            }, "models/best_d_checkpoint.pth")

        if generator_epoch_loss < best_g_loss:
            best_g_loss = generator_epoch_loss
            torch.save({
                'generator': generator.state_dict(),
                'discriminator': discriminator.state_dict(),
                'optimizer_G_state_dict': optimizer_G.state_dict(),
                'optimizer_D_state_dict': optimizer_D.state_dict(),
                'epoch': epoch,
                'best_g_loss': best_g_loss,
                'best_d_loss': best_d_loss
            }, "models/best_g_checkpoint.pth")
```
If the current epoch's loss is better than the previous best loss, the model is saved as a checkpoint.

```python
        torch.save({
            'generator': generator.state_dict(),
            'discriminator': discriminator.state_dict(),
            'optimizer_G_state_dict': optimizer_G.state_dict(),
            'optimizer_D_state_dict': optimizer_D.state_dict(),
            'epoch': epoch,
            'best_g_loss': best_g_loss,
            'best_d_loss': best_d_loss
        }, last_checkpoint_dir)

        print(f"Saved last model after epoch {epoch}")
        print(f"Generated sample image at epoch {epoch}")
        show_fake_images(fake_images.cpu())
        print("------------------------------------------")
```
The model state is saved after every epoch to a file named last_checkpoint.pth, allowing training to resume later if interrupted. The generated images are displayed for visual inspection.

```python
    torch.save({
        'generator': generator.state_dict(),
        'discriminator': discriminator.state_dict(),
        'optimizer_G_state_dict': optimizer_G.state_dict(),
        'optimizer_D_state_dict': optimizer_D.state_dict(),
        'epoch': num_epochs - 1,
        'best_g_loss': best_g_loss,
        'best_d_loss': best_d_loss
    }, "models/final_checkpoint.pth")
    print("Saved final model after training ended")
```
Finally, after all epochs are completed, the final model is saved.

## Inference
For inference, you can load a pre-trained generator model and use it to remove backgrounds from new images. The resulting image is saved as 4 chanels (RGBA).

## Usage

### Training the Model
1. **Set Dataset Paths**: Update the paths to your datasets in the `bg_path` and `no_bg_path` variables.
2. **Run Training**: Execute the training cell in the notebook to start training the GAN model. The model will be saved periodically.

### Generating Images
To generate images with backgrounds removed:
1. **Load the Pre-trained Model**: Load the checkpoint of the trained generator model.
2. **Process and Generate**: Provide an input image, and the model will generate an image without a background.

```python
process_and_generate(input_image_path, output_image_path)
```

## Visualizing Predictions
You can visualize and compare the generated images with the original background images and the real images without backgrounds using the predict_and_compare function.

```python
predict_and_compare(test_loader, n_images=5)
```
## Results
The model is capable of effectively removing backgrounds from input images, as demonstrated by the predictions compared against the ground truth.

## Contributing
Contributions are welcome! If you have any ideas for improvements or new features, feel free to submit a pull request, open an issue or send an email to [tranducthuan220401@gmail.com](mailto:tranducthuan220401@gmail.com)

