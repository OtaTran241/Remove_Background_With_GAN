# Background Removal using GAN with PyTorch

This project implements a Generative Adversarial Network (GAN) to perform background removal from images. The model is trained to generate images without backgrounds given images with backgrounds, effectively learning the task of background subtraction.

## Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
  - [Generator (GModel)](#generator-gmodel)
  - [Discriminator (DModel)](#discriminator-dmodel)
- [Training](#training)
- [Inference](#inference)
- [Dependencies](#dependencies)
- [Usage](#usage)
  - [Training the Model](#training-the-model)
  - [Generating Images](#generating-images)
- [Results](#results)
- [Contributing](#contributing)

## Project Overview
This project leverages a GAN consisting of a generator (`GModel`) and a discriminator (`DModel`) to remove backgrounds from images. The generator learns to produce images without backgrounds, while the discriminator differentiates between real images (with no background) and generated images.

## Dataset
The dataset used in this project consists of paired images:
- **Images with backgrounds**: Input images that contain the background.
- **Images without backgrounds**: Target images that do not have the background.

Dataset link [here](https://www.kaggle.com/datasets/cooperbuch/images-with-no-background-for-background-removal)

## Model Architecture

### Generator (GModel)
The generator is built using a U-Net-like architecture with encoder-decoder layers:
- **Encoder**: Consists of convolutional layers to downsample the input image.
- **Decoder**: Uses transpose convolutions to upsample the image, producing an output image without background.

### Discriminator (DModel)
The discriminator is a convolutional neural network (CNN) designed to classify images as real (without background) or fake (generated by the generator). It uses residual blocks to enhance feature extraction.

## Training
The training process alternates between updating the generator and the discriminator:
1. **Discriminator Update**: Trained to distinguish real images from generated images.
2. **Generator Update**: Trained to produce realistic images that the discriminator cannot distinguish from real images.

Binary Cross-Entropy (BCE) and L1 losses are used to guide the training of the discriminator and generator, respectively.

### Training Hyperparameters
- **Batch Size**: 55
- **Epochs**: 200
- **Learning Rate**:
  - Generator: 1e-4
  - Discriminator: 1e-5

## Inference
For inference, you can load a pre-trained generator model and use it to remove backgrounds from new images. The resulting image is saved as 4 chanels (RGBA).

## Usage

### Training the Model
1. **Set Dataset Paths**: Update the paths to your datasets in the `bg_path` and `no_bg_path` variables.
2. **Run Training**: Execute the training cell in the notebook to start training the GAN model. The model will be saved periodically.

### Generating Images
To generate images with backgrounds removed:
1. **Load the Pre-trained Model**: Load the checkpoint of the trained generator model.
2. **Process and Generate**: Provide an input image, and the model will generate an image without a background.

```python
process_and_generate(input_image_path, output_image_path)
```

## Visualizing Predictions
You can visualize and compare the generated images with the original background images and the real images without backgrounds using the predict_and_compare function.

```python
predict_and_compare(test_loader, n_images=5)
```
## Results
The model is capable of effectively removing backgrounds from input images, as demonstrated by the predictions compared against the ground truth.

## Contributing
Contributions are welcome! If you have any ideas for improvements or new features, feel free to submit a pull request or open an issue.
